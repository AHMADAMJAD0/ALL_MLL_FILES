{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Sentiment Analysis on CSV (IMDB format)\n",
        "# - Columns expected: 'review', 'sentiment' (values: 'positive'/'negative')\n",
        "# - Prints accuracy (train/test split)\n",
        "# - Saves predictions for ALL rows (CSV + Excel)\n",
        "# ============================\n",
        "\n",
        "import os, re, time, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Load CSV\n",
        "# ----------------------------\n",
        "# Change this path if needed\n",
        "CSV_PATH = \"IMDB Dataset.csv\"   # e.g., \"/content/IMDB Dataset.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"‚úÖ CSV loaded:\", df.shape)\n",
        "\n",
        "# Sanity check for expected columns\n",
        "if not {'review', 'sentiment'}.issubset(df.columns):\n",
        "    raise ValueError(\"CSV must have columns: 'review' and 'sentiment'\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Minimal cleaning\n",
        "# ----------------------------\n",
        "def basic_clean(s: str) -> str:\n",
        "    s = str(s)\n",
        "    s = re.sub(r\"<.*?>\", \" \", s)                 # remove HTML\n",
        "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)      # remove URLs\n",
        "    s = re.sub(r\"[^A-Za-z0-9\\s']\", \" \", s)       # keep alnum + apostrophes\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "df['review_clean'] = df['review'].astype(str).apply(basic_clean)\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Map labels to 0/1\n",
        "# ----------------------------\n",
        "label_map = {'negative': 0, 'positive': 1}\n",
        "df['label'] = df['sentiment'].astype(str).str.lower().map(label_map)\n",
        "if df['label'].isna().any():\n",
        "    raise ValueError(\"Labels must be 'positive' or 'negative'.\")\n",
        "\n",
        "print(\"Class counts:\", df['label'].value_counts().to_dict())\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Train/Test split\n",
        "# ----------------------------\n",
        "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
        "    df['review_clean'].values,\n",
        "    df['label'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label'].values\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Vectorize (TF-IDF)\n",
        "# ----------------------------\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=20000,\n",
        "    ngram_range=(1,2),\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "X_train = vectorizer.fit_transform(X_train_text)\n",
        "X_val   = vectorizer.transform(X_val_text)\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Train Logistic Regression\n",
        "# ----------------------------\n",
        "# 'saga' is fast for large sparse data and supports predict_proba\n",
        "lr = LogisticRegression(solver='saga', max_iter=2000, n_jobs=-1)\n",
        "t0 = time.time()\n",
        "lr.fit(X_train, y_train)\n",
        "print(f\"‚è± Train time: {time.time()-t0:.2f}s\")\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Evaluate\n",
        "# ----------------------------\n",
        "y_pred = lr.predict(X_val)\n",
        "acc = accuracy_score(y_val, y_pred)\n",
        "print(f\"üéØ Validation Accuracy (LR): {acc:.4f}\")\n",
        "\n",
        "print(\"üìä Classification Report (LR):\")\n",
        "print(classification_report(y_val, y_pred, target_names=['negative','positive']))\n",
        "\n",
        "# ----------------------------\n",
        "# 8) Final predictions for ALL rows (optional but useful)\n",
        "#    Fit on ALL data, then predict for the whole CSV\n",
        "# ----------------------------\n",
        "X_all = vectorizer.fit_transform(df['review_clean'].values)\n",
        "lr.fit(X_all, df['label'].values)\n",
        "\n",
        "pred_all = lr.predict(X_all)\n",
        "df['PredLabel'] = pd.Series(pred_all).map({0:'negative', 1:'positive'})\n",
        "\n",
        "# Confidence (may not be perfect calibration; still useful)\n",
        "try:\n",
        "    prob_all = lr.predict_proba(X_all).max(axis=1)\n",
        "    df['Confidence'] = prob_all\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ----------------------------\n",
        "# 9) Save outputs\n",
        "# ----------------------------\n",
        "out_cols = ['review', 'PredLabel']\n",
        "if 'Confidence' in df.columns:\n",
        "    out_cols.append('Confidence')\n",
        "\n",
        "csv_out = \"Sentiment_Predictions.csv\"\n",
        "xlsx_out = \"Sentiment_Predictions.xlsx\"\n",
        "\n",
        "df[out_cols].to_csv(csv_out, index=False, encoding='utf-8-sig')\n",
        "try:\n",
        "    df[out_cols].to_excel(xlsx_out, index=False)\n",
        "    print(f\"üíæ Saved:\\n - {csv_out}\\n - {xlsx_out}\")\n",
        "except Exception as e:\n",
        "    print(f\"üíæ Saved:\\n - {csv_out}\\n - (Excel skipped: {e})\")\n",
        "\n",
        "# (Colab) auto-download\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(csv_out)\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "-8wZH80SwMAq",
        "outputId": "1f764f67-2892-46ab-bdad-7c877de053f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSV loaded: (50000, 2)\n",
            "Class counts: {1: 25000, 0: 25000}\n",
            "‚è± Train time: 4.68s\n",
            "üéØ Validation Accuracy (LR): 0.9052\n",
            "üìä Classification Report (LR):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.90      0.90      5000\n",
            "    positive       0.90      0.91      0.91      5000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "üíæ Saved:\n",
            " - Sentiment_Predictions.csv\n",
            " - (Excel skipped: First things first: I'm not a conservative. And even though I would never refer to myself as a liberal or a Democrat, I was opposed to the war in Iraq from day one. I think it's safe to say John Cusack and I would probably see eye-to-eye on politics, in fact, I'm sure we'd become drinking buddies if we ever got to talking about how great Adam Curtis' BBC docs are. My point is this: don't discredit this review by thinking I'm not a part of the choir Cusack is preaching to in War, Inc. There's no question WI's politics are tailored to appeal to my demographic, but the problem is, the tailoring is substandard and the the film Cusack co- wrote, produced and stars in, fits worse than a cheap suit.<br /><br />As they say \"the road to hell is paved with good intentions.\" Cusack, his co-writers, director Joshua Seftel and even the actors involved, no doubt had every intention of making an anti- war film every bit as biting and funny as Robert Altman's M*A*S*H, unfortunately for the viewer, they ended up with one as unfunny and unintelligent as Michael Moore's Canadian Bacon.<br /><br />The current state of US politics, foreign policy and the war \"effort\" is already absurd and, as a result, tragic, pathetic and, regrettably comical -- just watch The Daily Show and see for yourself. The bottom line is: you can't write material as funny as what the Bush administration provides us on a daily basis, so why try to compete?<br /><br />The main problem with WI is that it feels it was put together in a hurry. To get it done, Cusack basically cannibalized Grosse Pointe Blank (one of his best films), changed the setting and crammed in a shopping list of ideas lifted from the collected works of Naomi Klein. Most of these ideas are rammed down your throat in the first twenty minutes of the film and what makes them so obnoxious is none of the jokes or gags or deliberately obvious references to Halliburton, the Neo-Cons and the US occupation of Iraq, are imaginative, clever or funny. The writers are so blinded by their \u0010own dogma they felt that by simply referencing these issues the film would be funny and subversive. The trouble is...it isn't. By now these ideas are yesterday's news and unless you've been living under or rock or are so blinded by ignorance, denial and sheer stupidity (read: a right-wing Christian), these jokes insultingly simple.<br /><br />Perhaps WI would work if it was more nuanced, subversive, offensive and fattened up with detailed research/insights into the Occupation. As it is, the jokes and sight gags are all surface and are so bad, with so little finesse, subtlety or satirical wickedness, they did little more than make me groan. Homer Simpson once said \"It's funny 'cause it's true\" and The Daily Show proves this every night; War, Inc. however proves that just because it's true doesn't make it funny. The bottom line: hyperbole isn't required when it comes to lampooning US/Neo-Conservative politics...it's already a big enough joke.<br /><br />http://eattheblinds.blogspot.com/ cannot be used in worksheets.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d01f0e12-f81e-408e-b1cb-a9affa69bcf2\", \"Sentiment_Predictions.csv\", 67156107)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-50awMfjwRHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}